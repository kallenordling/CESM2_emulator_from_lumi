import torch
from torch import Tensor
from tqdm import tqdm
from diffusers import DDPMScheduler
from custom_diffusers.continuous_ddpm import ContinuousDDPM
from einops import reduce

from captum.attr import IntegratedGradients

def model_forward(cond):
    input_tensor = torch.cat([gen_sample, cond], dim=1)
    return model.ema_model(input_tensor, t).pow(2).mean()



def generate_samples2(
    clean_samples: Tensor,
    cond_map: Tensor,
    scheduler: DDPMScheduler,
    sample_steps: int,
    model: torch.nn.Module,
    disable=False,explain=True
):
    """Generate samples from a trained model (optimized)."""
    # ===== EMA SAMPLING ASSERT =====
    assert hasattr(model, "parameters"), "model is not a torch module?"

    # Hard safety check: this MUST be ema_model
    if hasattr(model, "ema_model"):
        raise RuntimeError(
            "X You passed EMA wrapper instead of ema_model. "
            "Call generate_samples*(..., model=ema.ema_model)"
        )

    print("[GEN_UTILS] Sampling from model:", type(model))
    device = next(model.parameters()).device
    dtype = next(model.parameters()).dtype

    # Use only the first channel but avoid unnecessary copies
    # clean_samples: (B, C, T, H, W) -> (B, 1, T, H, W)
    clean_samples = clean_samples[:, 0:1, ...]  # slice keeps view if possible

    # Cond map to device once
    cond_map = cond_map.to(device=device, dtype=dtype, non_blocking=True)


    # Start from pure noise
    gen_sample = torch.randn_like(clean_samples, device=device, dtype=dtype)

    # IMPORTANT: timesteps are assumed to be set OUTSIDE this function
    timesteps = scheduler.timesteps.to(device)

    # Precompute continuous timesteps ONLY ONCE if needed
    if isinstance(scheduler, ContinuousDDPM):
        # steps has length sample_steps + 1, but we only index by timesteps
        steps = torch.linspace(1.0, 0.0, sample_steps + 1, device=device)
        # log_snr for all timesteps in one go
        t_all = scheduler.log_snr(steps[timesteps])  # shape: (n_steps,)

    batch_size = clean_samples.shape[0]
    sal_co2 = None
    sal_sul = None
    if explain:
        cond_map = cond_map.detach().clone().requires_grad_(True)
        gen_sample_fixed = gen_sample.detach().clone()
        t_fixed = scheduler.timesteps[0]  # or a representative timestep

        # One forward pass with gradients
        output = model(
            gen_sample_fixed,
            t_fixed,
            cond_map=cond_map
        )

        output_scalar = output.pow(2).mean()  # or .sum()
        output_scalar.backward()
    
        saliency = cond_map.grad.detach()  # shape: [B, 2, T, H, W]

        # Optional: average over time
        sal_co2 = saliency[0, 0].abs().mean(dim=0).cpu().numpy()  # [H, W]
        sal_sul = saliency[0, 1].abs().mean(dim=0).cpu().numpy()

    with torch.inference_mode():

        for step_idx, t_idx in tqdm(
            enumerate(timesteps),
            total=len(timesteps),
            desc="Sampling",
            disable=disable,
        ):
            if isinstance(scheduler, ContinuousDDPM):
                # Repeat scalar for batch
                t = t_all[step_idx].expand(batch_size)
            else:
                t = t_idx

            # Model forward
            output = model(
                gen_sample,
                t,
                cond_map=cond_map,
            )

            # One reverse diffusion step
            gen_sample = scheduler.step(
                output,
                timestep=t_idx,
                sample=gen_sample
            ).prev_sample

    return gen_sample,sal_co2,sal_sul


@torch.inference_mode()
def generate_samples(
    clean_samples: Tensor,
    cond_map: Tensor,
    scheduler: DDPMScheduler,
    sample_steps: int,
    model: torch.nn.Module,
    disable=False,
):
    """Generate samples from a trained model"""
    device = next(model.parameters()).device
    dtype  = next(model.parameters()).dtype


    # Average across the time dimension, and then repeat along the time dimension
    # To get our average monthly conditioning map
    #cond_map = reduce(clean_samples, "b v t h w -> b v 1 h w", "mean").repeat(
    #    1, 1, clean_samples.shape[-3], 1, 1
    #)

    # Sample noise that we'll add to the clean images
    print(cond_map.shape,"cond map shape")
    clean_samples= clean_samples[:,0,:,:,:].unsqueeze(1)
    gen_sample = torch.randn_like(clean_samples)
    gen_samples = gen_sample.to(device=device, dtype=dtype)
    cond_map      = cond_map.to(device=device, dtype=dtype)
    #print(gen_sample.shape)
    #print(cond_map.shape)
    # set step values
    scheduler.set_timesteps(sample_steps)

    # Run the diffusion process in reverse
    for i in tqdm(
        scheduler.timesteps,
        "Sampling",
        disable=disable,
    ):
        # If we are using a continuous scheduler, convert the timestep to a log_snr
        if isinstance(scheduler, ContinuousDDPM):
            steps = torch.linspace(1.0, 0.0, sample_steps + 1, device=gen_sample.device)
            t = scheduler.log_snr(steps[i]).repeat(clean_samples.shape[0])
        else:
            t = i
        #print(i)
        output = model(
            gen_sample,
            t,
            cond_map=cond_map,
        )

        gen_sample = scheduler.step(output, timestep=i, sample=gen_sample).prev_sample

    return gen_sample
